{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/balanced_data.csv\")\n",
        "df.shape"
      ],
      "metadata": {
        "id": "H6DA4xSx2wGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "9N9ZWWl-2qwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your data\n",
        "X = df.drop(\"FLAG\", axis=1)\n",
        "y = df[\"FLAG\"]"
      ],
      "metadata": {
        "id": "FLtd24XDytWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Uud3DKMxzDNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import ElasticNetCV\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "import shap\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define best hyperparameters for Random Forest\n",
        "rf_params = {'max_depth': 10, 'max_features': 0.3139538085100205,\n",
        "             'min_samples_leaf': 1.7307339350609041, 'min_samples_split': 14.052804288439336,\n",
        "             'n_estimators': 123}\n",
        "best_rf = RandomForestClassifier(**rf_params)\n",
        "\n",
        "# Define best hyperparameters for XGBoost\n",
        "xgb_params = {'colsample_bytree': 0.9729370974093524, 'learning_rate': 0.48726788904554486,\n",
        "              'max_depth': 3, 'min_child_weight': 4, 'n_estimators': 105, 'subsample': 0.894412699905483}\n",
        "best_xgb = XGBClassifier(**xgb_params)\n",
        "\n",
        "# Define best hyperparameters for Neural Network\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "    model.add(Dense(units=128, activation='relu'))\n",
        "    model.add(Dense(units=1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "best_nn = create_model()\n",
        "\n",
        "# Create the stacking ensemble model with Elastic Net\n",
        "estimators = [\n",
        "    ('rf', best_rf),\n",
        "    ('xgb', best_xgb),\n",
        "    ('nn', best_nn)\n",
        "]\n",
        "stacking_model = StackingClassifier(estimators=estimators, final_estimator=ElasticNetCV())\n",
        "\n",
        "# Train the stacking model\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the stacking model\n",
        "y_pred = stacking_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Explain feature importance using SHAP\n",
        "explainer = shap.Explainer(stacking_model)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n",
        "\n",
        "# Explain feature importance using LIME\n",
        "lime_explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X_train.columns.tolist(), class_names=['0', '1'], mode='classification')\n",
        "lime_exp = lime_explainer.explain_instance(X_test.iloc[0], stacking_model.predict_proba, num_features=10)\n",
        "lime_exp.show_in_notebook()\n",
        "\n",
        "# Explain feature importance using ELI5\n",
        "perm = PermutationImportance(stacking_model, random_state=42).fit(X_test, y_test)\n",
        "eli5.show_weights(perm, feature_names=X_test.columns.tolist())"
      ],
      "metadata": {
        "id": "yciTPLfGxrEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate evaluation metrics\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "#auroc = roc_auc_score(y_test, best_xgb_clf.predict_proba(X_test)[:, 1])\n",
        "#mcc = matthews_corrcoef(y_test, y_pred)\n",
        "#brier_score = brier_score_loss(y_test, best_xgb_clf.predict_proba(X_test)[:, 1])\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {acc}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "#print(f\"AUROC: {auroc}\")\n",
        "#print(f\"MCC: {mcc}\")\n",
        "#print(f\"Brier Score: {brier_score}\")\n",
        "print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "# Plot Confusion Matrix Heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vxmUT2Bh2M7D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}